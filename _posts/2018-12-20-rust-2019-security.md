---
layout: post
title: "Rust 2019: security"
description: ""
category:
tags: [rust, rust 2019, security, memory corruption, exploit]
---

### Introduction

I've decided to write this blog post because this is one of Rust's main selling points and the most important to me: **memory safety without GC**.

The truth of that statement relies on writing code in purely safe Rust. Unfortunately, that's not a real world case scenario. A few crates will use unsafe but most of them will depend on at least one crate which uses unsafe.

This is not something new and working groups in Rust are tackling this problem from different angles: Security WG, RustBelt, Formal Verification WG and XXX_

### Unsafe Rust

A big part of the unsafe code I usually see can fit into these categories:

*) Integrating Rust with other components through FFI
*) Functionality not available in `std` (standard library)
*) Implement [send and sync](https://doc.rust-lang.org/nightly/nomicon/send-and-sync.html) (I'm not discussing it here)
*) Optimizations that cannot be expressed through the type system

#### Rust+FFI

The community has already learned that ***Rewrite it in Rust*** doesn't scale and it's a dangerous meme. One that other developers usually laugh at.

On the other hand, one of the things that we are learning is that gradually replacing C/C++ with Rust code works quite well. The same happens with encapsulating C code with safe Rust abstractions.

For this, we use [ffi](https://doc.rust-lang.org/nightly/nomicon/ffi.html) usually generated by [bindgen](https://github.com/rust-lang/rust-bindgen).

A problem that has no practical solution yet is how can we guarantee safety in these cases. This happens in almost every programming language that supports FFI so a possible solution here might be able to help the others.

The way I see it being tackled is having isolation at the FFI level. Where either, we impose a serialization barrier to a process inside a sandbox, or use more modern compartmentalization technologies such as [CHERI](https://www.cl.cam.ac.uk/~kg365/pubs/201505-oakland2015-cheri-compartmentalization.pdf).

While isolating unsafe code (C/C++) into a sandbox might solve the problem and can probably be implemented *"easily"* through bindgen and other existing libraries, it will incur into performance penalty very quickly and could also open a Pandora box of other issues.

Also, to not degrade the security of the existing components, we have to be able to support all the memory corruption mitigations supported by the C and C++ compiles like (control flow integrity)[https://en.wikipedia.org/wiki/Control-flow_integrity]. In Microsoft we treat security very seriously and not being able to impose the full security mitigations spectrum on a component can hinder adoption.

#### Functionality not available in *std*

It's very hard to track which are these cases and even harder to decide which are worth adding to `core` or `std` so external libraries don't have to implement it themselves. There is also the question of *is it really worth putting everything in the standard library?*

Well, in my opinion, std is a form of endorsement over something being unsafe but safe.
[//]: <> (So functions used over the standard collection are probably worth putting in.)

An example I can think of now is casting between memory representations of the same size like `f64` to `u64` or `[u8;4]` as used in [byteorder](https://github.com/BurntSushi/byteorder). Something like a safe specialization of `mem::transmute` can probably help.

The Security WG is already looking for similar patterns so I'm very positive about it but, unfortunately, it's probably a never ending story.

#### Optimizations

I often see, that in hot-paths, developers tend to do nasty things to avoid having performance impact there. More often than not, the code is "safe" but uses `unsafe`.

One of the examples was that back when I reviewed [edgelet](https://github.com/Azure/iotedge/tree/master/edgelet)'s source code, I found that the only unsafe code outside of FFI was for copying data inside uninitialized buffers. While the operation of reading from these buffers is unsafe, writing to them isn't but it's not possible to specify it with the current types.

This particular example might fall inside the previous point but I think it deserves a distinction between *"unsafe because faster"* and *"unsafe because I can't safe"*.

### Others

#### Async/await

I'd like to see the whole async/await story improve with tokio adopting futures-0.3 and porting many of the derived crates to it as well. This year I tried using the new syntax with futures-0.3 but the ecosystem wasn't yet there. I don't have a strong opinion on how can this be helped though.

#### Fallible allocations

I'm not yet convinced by allocating is either succeed or crash. I worked in implementing the `try_alloc` [RFC]() for the different collections but didn't submit a stabilization PR because of concerns on [efforts]() trying to improve the [Allocator API]() breaking backwards compatibility through it.

#### A better IDE experience

Others already mentioned it, but I think we need RLS to continue improving through the great work that has been getting during the past years. Not being able to use, in my case, VSCode at its full experience is a little frustrating and hinders adoption.

### Conclusion

While many interesting things happened during 2018. I see 2019 as a period for improving the ecosystem and continue getting feedback on adoption blockers for bigger players.

In my case, because I'm in Microsoft and I'm pushing for adoption here, I think security should be a top priority if we want to go after *ugly and unsafe C and C++*.

Thanks for reading.

* Follow me in Twitter: [@snfernandez](https://twitter.com/snfernandez)
* Contact me at Gmail: sebanfernandez
* Secure is better: [GPG Key]({{ site.url }}/public/data/sebanfernandez_0xEB1C845F_pub.asc)
